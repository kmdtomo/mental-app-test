# éŸ³å£°æ„Ÿæƒ…èªè­˜æ©Ÿèƒ½ã®å®Ÿè£…æ‰‹é †

## æ¦‚è¦
éŸ³å£°æ—¥è¨˜ã‚¢ãƒ—ãƒªã«æ„Ÿæƒ…åˆ†ææ©Ÿèƒ½ã‚’è¿½åŠ ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…çŠ¶æ…‹ï¼ˆæ€’ã‚Šãƒ»å–œã³ãƒ»æ‚²ã—ã¿ï¼‰ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§åˆ†æã—ã¾ã™ã€‚

## Phase 1-A: æœ€å°æ§‹æˆã§ã®å®Ÿè£…

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
```
éŸ³å£°éŒ²éŸ³ï¼ˆWebMå½¢å¼ï¼‰
    â†“
/api/upload-audioï¼ˆæ—¢å­˜ï¼‰
    â†“
ä¸¦åˆ—å‡¦ç† â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
    â†“                        â†“
/api/whisperï¼ˆæ—¢å­˜ï¼‰    /api/analyze-emotionï¼ˆæ–°è¦ï¼‰
    â†“                        â†“
æ–‡å­—èµ·ã“ã—              æ„Ÿæƒ…åˆ†æ
    â†“                        â†“
Supabase DB ã«ä¿å­˜
```

## å®Ÿè£…æ‰‹é †

### 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã®æ‹¡å¼µ

dialogue_turnsãƒ†ãƒ¼ãƒ–ãƒ«ã«æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ï¼š

```sql
-- Supabase SQLã‚¨ãƒ‡ã‚£ã‚¿ã§å®Ÿè¡Œ
ALTER TABLE dialogue_turns
ADD COLUMN emotion_ang FLOAT,
ADD COLUMN emotion_hap FLOAT,
ADD COLUMN emotion_sad FLOAT,
ADD COLUMN emotion_primary VARCHAR(10);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
CREATE INDEX idx_dialogue_turns_emotion ON dialogue_turns(emotion_primary);
```

### 2. æ„Ÿæƒ…åˆ†æAPIã®ä½œæˆ

`/app/api/analyze-emotion/route.ts`ã‚’æ–°è¦ä½œæˆï¼š

```typescript
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@/lib/supabase/server';
import { cookies } from 'next/headers';
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

export async function POST(request: NextRequest) {
  console.log('=== Emotion Analysis API Called ===');
  
  try {
    const cookieStore = cookies();
    const supabase = createClient(cookieStore);
    
    // èªè¨¼ç¢ºèª
    const { data: { user }, error: authError } = await supabase.auth.getUser();
    if (authError || !user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    const { recordingId, filePath } = await request.json();
    
    // Supabaseã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å…¬é–‹URLã‚’å–å¾—
    const { data: { publicUrl } } = supabase.storage
      .from('voice-recordings')
      .getPublicUrl(filePath);
    
    // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    const tempPath = `/tmp/${recordingId}.webm`;
    await execAsync(`curl -o ${tempPath} "${publicUrl}"`);
    
    // Pythonæ„Ÿæƒ…åˆ†æå®Ÿè¡Œ
    const pythonPath = '/Users/komodatomo/Desktop/onsei-laboratory/vad_deeplearning';
    const { stdout } = await execAsync(
      `cd ${pythonPath} && python3 -c "
import sys
sys.path.append('.')
from inference import inference_core
result = inference_core('${tempPath}')
import json
print(json.dumps(result))
"`
    );
    
    const emotionResult = JSON.parse(stdout);
    
    // dialogue_turnsãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°
    const { error: updateError } = await supabase
      .from('dialogue_turns')
      .update({
        emotion_ang: emotionResult.ang,
        emotion_hap: emotionResult.hap,
        emotion_sad: emotionResult.sad,
        emotion_primary: emotionResult.emo
      })
      .eq('recording_id', recordingId);
    
    if (updateError) {
      console.error('DB update error:', updateError);
      return NextResponse.json({ error: updateError.message }, { status: 500 });
    }
    
    // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    await execAsync(`rm ${tempPath}`);
    
    return NextResponse.json({
      success: true,
      emotion: {
        ang: emotionResult.ang,
        hap: emotionResult.hap,
        sad: emotionResult.sad,
        primary: emotionResult.emo
      }
    });
    
  } catch (error) {
    console.error('Emotion analysis error:', error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Analysis failed' },
      { status: 500 }
    );
  }
}
```

### 3. VoiceDiaryPageã®æ›´æ–°

`/views/VoiceDiaryPage.tsx`ã«ä¸¦åˆ—å‡¦ç†ã‚’è¿½åŠ ï¼š

```typescript
// æ—¢å­˜ã®importã«è¿½åŠ 
interface EmotionResult {
  ang: number;
  hap: number;
  sad: number;
  primary: string;
}

// stateã«è¿½åŠ 
const [emotionResult, setEmotionResult] = useState<EmotionResult | null>(null);

// handleRecordingCompleteé–¢æ•°å†…ã§ä¸¦åˆ—å‡¦ç†
try {
  // ... æ—¢å­˜ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç† ...

  // 2. Whisperã¨Emotionåˆ†æã‚’ä¸¦åˆ—å®Ÿè¡Œ
  console.log('Step 2: Parallel processing - Whisper & Emotion Analysis...');
  
  const [whisperResponse, emotionResponse] = await Promise.all([
    // Whisper APIï¼ˆæ—¢å­˜ï¼‰
    fetch('/api/whisper', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      credentials: 'include',
      body: JSON.stringify({
        recordingId: uploadResult.recordingId,
        filePath: uploadResult.filePath,
        duration: duration,
      }),
    }),
    // Emotion Analysis APIï¼ˆæ–°è¦ï¼‰
    fetch('/api/analyze-emotion', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      credentials: 'include',
      body: JSON.stringify({
        recordingId: uploadResult.recordingId,
        filePath: uploadResult.filePath,
      }),
    })
  ]);
  
  if (!whisperResponse.ok) throw new Error('Whisper API failed');
  if (!emotionResponse.ok) throw new Error('Emotion API failed');
  
  const whisperData = await whisperResponse.json();
  const emotionData = await emotionResponse.json();
  
  setTranscription(whisperData.originalText);
  setEmotionResult(emotionData.emotion);
  
  // ... ç¶šãã®å‡¦ç† ...
```

### 4. UIè¡¨ç¤ºã®è¿½åŠ 

æ„Ÿæƒ…çµæœã‚’è¡¨ç¤ºã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è¿½åŠ ï¼š

```tsx
// VoiceDiaryPageå†…ã«è¿½åŠ 
{emotionResult && (
  <Card className="p-4 mt-4">
    <h3 className="text-sm font-semibold mb-2">æ„Ÿæƒ…åˆ†æçµæœ</h3>
    <div className="space-y-2">
      <div className="flex items-center justify-between">
        <span>ğŸ˜  æ€’ã‚Š</span>
        <span className="font-mono">{emotionResult.ang.toFixed(3)}</span>
      </div>
      <div className="flex items-center justify-between">
        <span>ğŸ˜Š å–œã³</span>
        <span className="font-mono">{emotionResult.hap.toFixed(3)}</span>
      </div>
      <div className="flex items-center justify-between">
        <span>ğŸ˜¢ æ‚²ã—ã¿</span>
        <span className="font-mono">{emotionResult.sad.toFixed(3)}</span>
      </div>
      <div className="mt-2 pt-2 border-t">
        <span className="text-sm text-gray-600">ä¸»è¦æ„Ÿæƒ…: </span>
        <span className="font-semibold">
          {emotionResult.primary === 'ang' && 'ğŸ˜  æ€’ã‚Š'}
          {emotionResult.primary === 'hap' && 'ğŸ˜Š å–œã³'}
          {emotionResult.primary === 'sad' && 'ğŸ˜¢ æ‚²ã—ã¿'}
          {emotionResult.primary === 'other' && 'ğŸ˜ ãã®ä»–'}
        </span>
      </div>
    </div>
  </Card>
)}
```

## ãƒ†ã‚¹ãƒˆæ‰‹é †

1. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æº–å‚™**
   ```bash
   # Supabase Dashboardã§ã‚¹ã‚­ãƒ¼ãƒã‚’æ›´æ–°
   ```

2. **ä¾å­˜é–¢ä¿‚ã®ç¢ºèª**
   ```bash
   # vad_deeplearningãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§
   cd /Users/komodatomo/Desktop/onsei-laboratory/vad_deeplearning
   pip3 install -r requirements.txt
   ```

3. **ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼èµ·å‹•**
   ```bash
   pnpm run dev
   ```

4. **å‹•ä½œç¢ºèª**
   - éŸ³å£°ã‚’éŒ²éŸ³
   - ä¸¦åˆ—å‡¦ç†ã®ç¢ºèªï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¿ãƒ–ï¼‰
   - æ„Ÿæƒ…åˆ†æçµæœã®è¡¨ç¤ºç¢ºèª
   - Supabaseã§ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç¢ºèª

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Pythonå®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã®å ´åˆ
```bash
# ãƒ‘ã‚¹ã‚’ç¢ºèª
which python3
# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ç¢ºèª
pip3 list | grep -E "torch|transformers|librosa"
```

### æ¨©é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
```bash
# ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¨©é™ç¢ºèª
ls -la /tmp/
```

### ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
```typescript
// API Routeå†…ã«è¿½åŠ 
console.log('Public URL:', publicUrl);
console.log('Python stdout:', stdout);
console.log('Emotion result:', emotionResult);
```

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆPhase 1-Bï¼‰

ãƒ‡ãƒ¼ã‚¿å–å¾—ãŒæˆåŠŸã—ãŸã‚‰ï¼š
1. Claudeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ„Ÿæƒ…æƒ…å ±ã‚’è¿½åŠ 
2. æ„Ÿæƒ…ã«åŸºã¥ã„ãŸå…±æ„Ÿçš„ãªå¿œç­”ã‚’å®Ÿè£…
3. æ„Ÿæƒ…å±¥æ­´ã®å¯è¦–åŒ–æ©Ÿèƒ½

## Phase 2: Lambdaç§»è¡Œ

ãƒ­ãƒ¼ã‚«ãƒ«å‹•ä½œç¢ºèªå¾Œï¼š
1. Lambdaé–¢æ•°ã®ä½œæˆ
2. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®EFSé…ç½®
3. API Gatewayã®è¨­å®š
4. ç’°å¢ƒå¤‰æ•°ã®ç§»è¡Œ